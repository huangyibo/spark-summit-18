Spark Executor Command: "/usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java" "-cp" "/databricks/spark/dbconf/log4j/executor/:/databricks/spark/dbconf/jets3t/:/databricks/spark/dbconf/hadoop/:/databricks/hive/conf/:/databricks/jars/api-base--api-base_java-spark_2.3_2.11_deploy.jar:/databricks/jars/api-base--api-base-spark_2.3_2.11_deploy.jar:/databricks/jars/api--rpc--rpc_parser-spark_2.3_2.11_deploy.jar:/databricks/jars/chauffeur-api--api--endpoints--endpoints-spark_2.3_2.11_deploy.jar:/databricks/jars/chauffeur-api--chauffeur-api-spark_2.3_2.11_deploy.jar:/databricks/jars/common--client--client-spark_2.3_2.11_deploy.jar:/databricks/jars/common--common-spark_2.3_2.11_deploy.jar:/databricks/jars/common--credentials--credentials-spark_2.3_2.11_deploy.jar:/databricks/jars/common--hadoop--hadoop-spark_2.3_2.11_deploy.jar:/databricks/jars/common--lazy--lazy_2.11_deploy.jar:/databricks/jars/common--libcommon_resources.jar:/databricks/jars/common--path--path-spark_2.3_2.11_deploy.jar:/databricks/jars/common--rate-limiter--rate-limiter-spark_2.3_2.11_deploy.jar:/databricks/jars/common--storage--storage-spark_2.3_2.11_deploy.jar:/databricks/jars/daemon--data--client--client-spark_2.3_2.11_deploy.jar:/databricks/jars/daemon--data--client--conf--conf-spark_2.3_2.11_deploy.jar:/databricks/jars/daemon--data--client--utils-spark_2.3_2.11_deploy.jar:/databricks/jars/daemon--data--data-common--data-common-spark_2.3_2.11_deploy.jar:/databricks/jars/dbfs--utils--dbfs-utils-spark_2.3_2.11_deploy.jar:/databricks/jars/extern--acl--auth--auth_2.11_deploy.jar:/databricks/jars/extern--extern-spark_2.3_2.11_deploy.jar:/databricks/jars/extern--libaws-regions.jar:/databricks/jars/----jackson_annotations_shaded--libjackson-annotations.jar:/databricks/jars/----jackson_core_shaded--libjackson-core.jar:/databricks/jars/----jackson_databind_shaded--libjackson-databind.jar:/databricks/jars/----jackson_datatype_joda_shaded--libjackson-datatype-joda.jar:/databricks/jars/jsonutil--jsonutil-spark_2.3_2.11_deploy.jar:/databricks/jars/logging--log4j-mod--log4j-mod-spark_2.3_2.11_deploy.jar:/databricks/jars/logging--utils--logging-utils-spark_2.3_2.11_deploy.jar:/databricks/jars/s3commit--client--client-spark_2.3_2.11_deploy.jar:/databricks/jars/s3--s3-spark_2.3_2.11_deploy.jar:/databricks/jars/secret-manager--api--api-spark_2.3_2.11_deploy.jar:/databricks/jars/spark--common--spark-common-spark_2.3_2.11_deploy.jar:/databricks/jars/spark--conf-reader--conf-reader_lib-spark_2.3_2.11_deploy.jar:/databricks/jars/spark--dbutils--dbutils-api-spark_2.3_2.11_deploy.jar:/databricks/jars/spark--driver--antlr--parser-spark_2.3_2.11_deploy.jar:/databricks/jars/spark--driver--common--driver-common-spark_2.3_2.11_deploy.jar:/databricks/jars/spark--driver--display--display-spark_2.3_2.11_deploy.jar:/databricks/jars/spark--driver--driver-spark_2.3_2.11_deploy.jar:/databricks/jars/spark--driver--events-spark_2.3_2.11_deploy.jar:/databricks/jars/spark--driver--ml--ml-spark_2.3_2.11_deploy.jar:/databricks/jars/spark--driver--secret-redaction-spark_2.3_2.11_deploy.jar:/databricks/jars/spark--driver--spark--resources-resources.jar:/databricks/jars/spark--maven-trees--spark_2.3--antlr--antlr--antlr__antlr__2.7.7.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--amazon-kinesis-client--com.amazonaws__amazon-kinesis-client__1.7.3.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-autoscaling--com.amazonaws__aws-java-sdk-autoscaling__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-cloudformation--com.amazonaws__aws-java-sdk-cloudformation__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-cloudfront--com.amazonaws__aws-java-sdk-cloudfront__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-cloudhsm--com.amazonaws__aws-java-sdk-cloudhsm__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-cloudsearch--com.amazonaws__aws-java-sdk-cloudsearch__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-cloudtrail--com.amazonaws__aws-java-sdk-cloudtrail__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-cloudwatch--com.amazonaws__aws-java-sdk-cloudwatch__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-cloudwatchmetrics--com.amazonaws__aws-java-sdk-cloudwatchmetrics__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-codedeploy--com.amazonaws__aws-java-sdk-codedeploy__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-cognitoidentity--com.amazonaws__aws-java-sdk-cognitoidentity__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-cognitosync--com.amazonaws__aws-java-sdk-cognitosync__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-config--com.amazonaws__aws-java-sdk-config__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-core--com.amazonaws__aws-java-sdk-core__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-datapipeline--com.amazonaws__aws-java-sdk-datapipeline__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-directconnect--com.amazonaws__aws-java-sdk-directconnect__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-directory--com.amazonaws__aws-java-sdk-directory__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-dynamodb--com.amazonaws__aws-java-sdk-dynamodb__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-ec2--com.amazonaws__aws-java-sdk-ec2__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-ecs--com.amazonaws__aws-java-sdk-ecs__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-efs--com.amazonaws__aws-java-sdk-efs__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-elasticache--com.amazonaws__aws-java-sdk-elasticache__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-elasticbeanstalk--com.amazonaws__aws-java-sdk-elasticbeanstalk__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-elasticloadbalancing--com.amazonaws__aws-java-sdk-elasticloadbalancing__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-elastictranscoder--com.amazonaws__aws-java-sdk-elastictranscoder__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-emr--com.amazonaws__aws-java-sdk-emr__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-glacier--com.amazonaws__aws-java-sdk-glacier__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-iam--com.amazonaws__aws-java-sdk-iam__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-importexport--com.amazonaws__aws-java-sdk-importexport__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-kinesis--com.amazonaws__aws-java-sdk-kinesis__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-kms--com.amazonaws__aws-java-sdk-kms__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-lambda--com.amazonaws__aws-java-sdk-lambda__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-logs--com.amazonaws__aws-java-sdk-logs__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-machinelearning--com.amazonaws__aws-java-sdk-machinelearning__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-opsworks--com.amazonaws__aws-java-sdk-opsworks__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-rds--com.amazonaws__aws-java-sdk-rds__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-redshift--com.amazonaws__aws-java-sdk-redshift__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-route53--com.amazonaws__aws-java-sdk-route53__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-s3--com.amazonaws__aws-java-sdk-s3__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-ses--com.amazonaws__aws-java-sdk-ses__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-simpledb--com.amazonaws__aws-java-sdk-simpledb__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-simpleworkflow--com.amazonaws__aws-java-sdk-simpleworkflow__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-sns--com.amazonaws__aws-java-sdk-sns__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-sqs--com.amazonaws__aws-java-sdk-sqs__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-ssm--com.amazonaws__aws-java-sdk-ssm__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-storagegateway--com.amazonaws__aws-java-sdk-storagegateway__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-sts--com.amazonaws__aws-java-sdk-sts__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-support--com.amazonaws__aws-java-sdk-support__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-swf-libraries--com.amazonaws__aws-java-sdk-swf-libraries__1.11.22.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--aws-java-sdk-workspaces--com.amazonaws__aws-java-sdk-workspaces__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.amazonaws--jmespath-java--com.amazonaws__jmespath-java__1.11.253.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.carrotsearch--hppc--com.carrotsearch__hppc__0.7.2.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.chuusai--shapeless_2.11--com.chuusai__shapeless_2.11__2.3.2.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.clearspring.analytics--stream--com.clearspring.analytics__stream__2.7.0.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.databricks--dbml-local_2.11--com.databricks__dbml-local_2.11__0.3.0-db1-spark2.3.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.databricks--dbml-local_2.11-tests--com.databricks__dbml-local_2.11-tests__0.3.0-db1-spark2.3.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.databricks--jets3t--com.databricks__jets3t__0.7.1-0.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.databricks--Rserve--com.databricks__Rserve__1.8-3.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.databricks.scalapb--compilerplugin_2.11--com.databricks.scalapb__compilerplugin_2.11__0.4.15-9.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.databricks.scalapb--scalapb-runtime_2.11--com.databricks.scalapb__scalapb-runtime_2.11__0.4.15-9.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.esotericsoftware--kryo-shaded--com.esotericsoftware__kryo-shaded__3.0.3.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.esotericsoftware--minlog--com.esotericsoftware__minlog__1.3.0.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.fasterxml--classmate--com.fasterxml__classmate__1.0.0.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.fasterxml.jackson.core--jackson-annotations--com.fasterxml.jackson.core__jackson-annotations__2.6.7.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.fasterxml.jackson.core--jackson-core--com.fasterxml.jackson.core__jackson-core__2.6.7.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.fasterxml.jackson.core--jackson-databind--com.fasterxml.jackson.core__jackson-databind__2.6.7.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.fasterxml.jackson.dataformat--jackson-dataformat-cbor--com.fasterxml.jackson.dataformat__jackson-dataformat-cbor__2.6.7.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.fasterxml.jackson.datatype--jackson-datatype-joda--com.fasterxml.jackson.datatype__jackson-datatype-joda__2.6.7.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.fasterxml.jackson.module--jackson-module-paranamer--com.fasterxml.jackson.module__jackson-module-paranamer__2.6.7.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.fasterxml.jackson.module--jackson-module-scala_2.11--com.fasterxml.jackson.module__jackson-module-scala_2.11__2.6.7.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.github.fommil--jniloader--com.github.fommil__jniloader__1.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.github.fommil.netlib--core--com.github.fommil.netlib__core__1.1.2.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.github.fommil.netlib--native_ref-java--com.github.fommil.netlib__native_ref-java__1.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.github.fommil.netlib--native_ref-java-natives--com.github.fommil.netlib__native_ref-java-natives__1.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.github.fommil.netlib--native_system-java--com.github.fommil.netlib__native_system-java__1.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.github.fommil.netlib--native_system-java-natives--com.github.fommil.netlib__native_system-java-natives__1.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.github.fommil.netlib--netlib-native_ref-linux-x86_64-natives--com.github.fommil.netlib__netlib-native_ref-linux-x86_64-natives__1.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.github.fommil.netlib--netlib-native_system-linux-x86_64-natives--com.github.fommil.netlib__netlib-native_system-linux-x86_64-natives__1.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.github.luben--zstd-jni--com.github.luben__zstd-jni__1.3.2-2.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.github.rwl--jtransforms--com.github.rwl__jtransforms__2.4.0.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.google.code.findbugs--jsr305--com.google.code.findbugs__jsr305__2.0.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.google.code.gson--gson--com.google.code.gson__gson__2.2.4.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.googlecode.javaewah--JavaEWAH--com.googlecode.javaewah__JavaEWAH__0.3.2.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.google.guava--guava--com.google.guava__guava__15.0.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.google.protobuf--protobuf-java--com.google.protobuf__protobuf-java__2.6.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.h2database--h2--com.h2database__h2__1.3.174.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.jamesmurty.utils--java-xmlbuilder--com.jamesmurty.utils__java-xmlbuilder__1.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.jcraft--jsch--com.jcraft__jsch__0.1.50.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.jolbox--bonecp--com.jolbox__bonecp__0.8.0.RELEASE.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.mchange--c3p0--com.mchange__c3p0__0.9.5.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.mchange--mchange-commons-java--com.mchange__mchange-commons-java__0.2.10.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.microsoft.azure--azure-data-lake-store-sdk--com.microsoft.azure__azure-data-lake-store-sdk__2.2.8.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.microsoft.sqlserver--mssql-jdbc--com.microsoft.sqlserver__mssql-jdbc__6.2.2.jre8.jar:/databricks/jars/spark--maven-trees--spark_2.3--commons-beanutils--commons-beanutils--commons-beanutils__commons-beanutils__1.7.0.jar:/databricks/jars/spark--maven-trees--spark_2.3--commons-beanutils--commons-beanutils-core--commons-beanutils__commons-beanutils-core__1.8.0.jar:/databricks/jars/spark--maven-trees--spark_2.3--commons-cli--commons-cli--commons-cli__commons-cli__1.2.jar:/databricks/jars/spark--maven-trees--spark_2.3--commons-codec--commons-codec--commons-codec__commons-codec__1.10.jar:/databricks/jars/spark--maven-trees--spark_2.3--commons-collections--commons-collections--commons-collections__commons-collections__3.2.2.jar:/databricks/jars/spark--maven-trees--spark_2.3--commons-configuration--commons-configuration--commons-configuration__commons-configuration__1.6.jar:/databricks/jars/spark--maven-trees--spark_2.3--commons-dbcp--commons-dbcp--commons-dbcp__commons-dbcp__1.4.jar:/databricks/jars/spark--maven-trees--spark_2.3--commons-digester--commons-digester--commons-digester__commons-digester__1.8.jar:/databricks/jars/spark--maven-trees--spark_2.3--commons-httpclient--commons-httpclient--commons-httpclient__commons-httpclient__3.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--commons-io--commons-io--commons-io__commons-io__2.4.jar:/databricks/jars/spark--maven-trees--spark_2.3--commons-lang--commons-lang--commons-lang__commons-lang__2.6.jar:/databricks/jars/spark--maven-trees--spark_2.3--commons-logging--commons-logging--commons-logging__commons-logging__1.1.3.jar:/databricks/jars/spark--maven-trees--spark_2.3--commons-net--commons-net--commons-net__commons-net__2.2.jar:/databricks/jars/spark--maven-trees--spark_2.3--commons-pool--commons-pool--commons-pool__commons-pool__1.5.4.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.ning--compress-lzf--com.ning__compress-lzf__1.0.3.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.sun.mail--javax.mail--com.sun.mail__javax.mail__1.5.2.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.thoughtworks.paranamer--paranamer--com.thoughtworks.paranamer__paranamer__2.8.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.trueaccord.lenses--lenses_2.11--com.trueaccord.lenses__lenses_2.11__0.3.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.twitter--chill_2.11--com.twitter__chill_2.11__0.8.4.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.twitter--chill-java--com.twitter__chill-java__0.8.4.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.twitter--parquet-hadoop-bundle--com.twitter__parquet-hadoop-bundle__1.6.0.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.twitter--util-app_2.11--com.twitter__util-app_2.11__6.23.0.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.twitter--util-core_2.11--com.twitter__util-core_2.11__6.23.0.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.twitter--util-jvm_2.11--com.twitter__util-jvm_2.11__6.23.0.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.typesafe--config--com.typesafe__config__1.2.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.typesafe.scala-logging--scala-logging-api_2.11--com.typesafe.scala-logging__scala-logging-api_2.11__2.1.2.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.typesafe.scala-logging--scala-logging-slf4j_2.11--com.typesafe.scala-logging__scala-logging-slf4j_2.11__2.1.2.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.univocity--univocity-parsers--com.univocity__univocity-parsers__2.5.9.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.vlkan--flatbuffers--com.vlkan__flatbuffers__1.2.0-3f79e055.jar:/databricks/jars/spark--maven-trees--spark_2.3--com.zaxxer--HikariCP--com.zaxxer__HikariCP__2.4.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--info.ganglia.gmetric4j--gmetric4j--info.ganglia.gmetric4j__gmetric4j__1.0.7.jar:/databricks/jars/spark--maven-trees--spark_2.3--io.airlift--aircompressor--io.airlift__aircompressor__0.8.jar:/databricks/jars/spark--maven-trees--spark_2.3--io.dropwizard.metrics--metrics-core--io.dropwizard.metrics__metrics-core__3.1.5.jar:/databricks/jars/spark--maven-trees--spark_2.3--io.dropwizard.metrics--metrics-ganglia--io.dropwizard.metrics__metrics-ganglia__3.1.5.jar:/databricks/jars/spark--maven-trees--spark_2.3--io.dropwizard.metrics--metrics-graphite--io.dropwizard.metrics__metrics-graphite__3.1.5.jar:/databricks/jars/spark--maven-trees--spark_2.3--io.dropwizard.metrics--metrics-healthchecks--io.dropwizard.metrics__metrics-healthchecks__3.1.5.jar:/databricks/jars/spark--maven-trees--spark_2.3--io.dropwizard.metrics--metrics-jetty9--io.dropwizard.metrics__metrics-jetty9__3.1.5.jar:/databricks/jars/spark--maven-trees--spark_2.3--io.dropwizard.metrics--metrics-json--io.dropwizard.metrics__metrics-json__3.1.5.jar:/databricks/jars/spark--maven-trees--spark_2.3--io.dropwizard.metrics--metrics-jvm--io.dropwizard.metrics__metrics-jvm__3.1.5.jar:/databricks/jars/spark--maven-trees--spark_2.3--io.dropwizard.metrics--metrics-log4j--io.dropwizard.metrics__metrics-log4j__3.1.5.jar:/databricks/jars/spark--maven-trees--spark_2.3--io.dropwizard.metrics--metrics-servlets--io.dropwizard.metrics__metrics-servlets__3.1.5.jar:/databricks/jars/spark--maven-trees--spark_2.3--io.netty--netty-all--io.netty__netty-all__4.1.17.Final.jar:/databricks/jars/spark--maven-trees--spark_2.3--io.netty--netty--io.netty__netty__3.9.9.Final.jar:/databricks/jars/spark--maven-trees--spark_2.3--io.prometheus.jmx--collector--io.prometheus.jmx__collector__0.7.jar:/databricks/jars/spark--maven-trees--spark_2.3--io.prometheus--simpleclient_common--io.prometheus__simpleclient_common__0.0.16.jar:/databricks/jars/spark--maven-trees--spark_2.3--io.prometheus--simpleclient_dropwizard--io.prometheus__simpleclient_dropwizard__0.0.16.jar:/databricks/jars/spark--maven-trees--spark_2.3--io.prometheus--simpleclient--io.prometheus__simpleclient__0.0.16.jar:/databricks/jars/spark--maven-trees--spark_2.3--io.prometheus--simpleclient_servlet--io.prometheus__simpleclient_servlet__0.0.16.jar:/databricks/jars/spark--maven-trees--spark_2.3--javax.activation--activation--javax.activation__activation__1.1.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--javax.annotation--javax.annotation-api--javax.annotation__javax.annotation-api__1.2.jar:/databricks/jars/spark--maven-trees--spark_2.3--javax.el--javax.el-api--javax.el__javax.el-api__2.2.4.jar:/databricks/jars/spark--maven-trees--spark_2.3--javax.jdo--jdo-api--javax.jdo__jdo-api__3.0.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--javax.servlet--javax.servlet-api--javax.servlet__javax.servlet-api__3.1.0.jar:/databricks/jars/spark--maven-trees--spark_2.3--javax.servlet.jsp--jsp-api--javax.servlet.jsp__jsp-api__2.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--javax.transaction--jta--javax.transaction__jta__1.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--javax.validation--validation-api--javax.validation__validation-api__1.1.0.Final.jar:/databricks/jars/spark--maven-trees--spark_2.3--javax.ws.rs--javax.ws.rs-api--javax.ws.rs__javax.ws.rs-api__2.0.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--javax.xml.bind--jaxb-api--javax.xml.bind__jaxb-api__2.2.2.jar:/databricks/jars/spark--maven-trees--spark_2.3--javax.xml.stream--stax-api--javax.xml.stream__stax-api__1.0-2.jar:/databricks/jars/spark--maven-trees--spark_2.3--javolution--javolution--javolution__javolution__5.5.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--jline--jline--jline__jline__2.11.jar:/databricks/jars/spark--maven-trees--spark_2.3--joda-time--joda-time--joda-time__joda-time__2.9.3.jar:/databricks/jars/spark--maven-trees--spark_2.3--log4j--apache-log4j-extras--log4j__apache-log4j-extras__1.2.17.jar:/databricks/jars/spark--maven-trees--spark_2.3--log4j--log4j--log4j__log4j__1.2.17.jar:/databricks/jars/spark--maven-trees--spark_2.3--net.hydromatic--eigenbase-properties--net.hydromatic__eigenbase-properties__1.1.5.jar:/databricks/jars/spark--maven-trees--spark_2.3--net.iharder--base64--net.iharder__base64__2.3.8.jar:/databricks/jars/spark--maven-trees--spark_2.3--net.java.dev.jets3t--jets3t--net.java.dev.jets3t__jets3t__0.9.4.jar:/databricks/jars/spark--maven-trees--spark_2.3--net.razorvine--pyrolite--net.razorvine__pyrolite__4.13.jar:/databricks/jars/spark--maven-trees--spark_2.3--net.sf.jpam--jpam--net.sf.jpam__jpam__1.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--net.sf.opencsv--opencsv--net.sf.opencsv__opencsv__2.3.jar:/databricks/jars/spark--maven-trees--spark_2.3--net.sf.supercsv--super-csv--net.sf.supercsv__super-csv__2.2.0.jar:/databricks/jars/spark--maven-trees--spark_2.3--net.sourceforge.f2j--arpack_combined_all--net.sourceforge.f2j__arpack_combined_all__0.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.acplt--oncrpc--org.acplt__oncrpc__1.0.7.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.antlr--antlr4-runtime--org.antlr__antlr4-runtime__4.7.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.antlr--antlr-runtime--org.antlr__antlr-runtime__3.4.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.antlr--ST4--org.antlr__ST4__4.0.4.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.antlr--stringtemplate--org.antlr__stringtemplate__3.2.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.ant--ant-jsch--org.apache.ant__ant-jsch__1.9.2.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.ant--ant-launcher--org.apache.ant__ant-launcher__1.9.2.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.ant--ant--org.apache.ant__ant__1.9.2.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.arrow--arrow-format--org.apache.arrow__arrow-format__0.8.0.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.arrow--arrow-memory--org.apache.arrow__arrow-memory__0.8.0.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.arrow--arrow-vector--org.apache.arrow__arrow-vector__0.8.0.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.avro--avro-ipc--org.apache.avro__avro-ipc__1.7.7.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.avro--avro-ipc-tests--org.apache.avro__avro-ipc-tests__1.7.7.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.avro--avro-mapred-hadoop2--org.apache.avro__avro-mapred-hadoop2__1.7.7.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.avro--avro--org.apache.avro__avro__1.7.7.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.calcite--calcite-avatica--org.apache.calcite__calcite-avatica__1.2.0-incubating.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.calcite--calcite-core--org.apache.calcite__calcite-core__1.2.0-incubating.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.calcite--calcite-linq4j--org.apache.calcite__calcite-linq4j__1.2.0-incubating.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.commons--commons-compress--org.apache.commons__commons-compress__1.4.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.commons--commons-crypto--org.apache.commons__commons-crypto__1.0.0.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.commons--commons-lang3--org.apache.commons__commons-lang3__3.5.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.commons--commons-math3--org.apache.commons__commons-math3__3.4.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.curator--curator-client--org.apache.curator__curator-client__2.7.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.curator--curator-framework--org.apache.curator__curator-framework__2.7.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.curator--curator-recipes--org.apache.curator__curator-recipes__2.7.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.derby--derby--org.apache.derby__derby__10.12.1.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.directory.api--api-asn1-api--org.apache.directory.api__api-asn1-api__1.0.0-M20.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.directory.api--api-util--org.apache.directory.api__api-util__1.0.0-M20.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.directory.server--apacheds-i18n--org.apache.directory.server__apacheds-i18n__2.0.0-M15.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.directory.server--apacheds-kerberos-codec--org.apache.directory.server__apacheds-kerberos-codec__2.0.0-M15.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.hadoop--hadoop-annotations--org.apache.hadoop__hadoop-annotations__2.7.3.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.hadoop--hadoop-auth--org.apache.hadoop__hadoop-auth__2.7.3.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.hadoop--hadoop-client--org.apache.hadoop__hadoop-client__2.7.3.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.hadoop--hadoop-common--org.apache.hadoop__hadoop-common__2.7.3.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.hadoop--hadoop-hdfs--org.apache.hadoop__hadoop-hdfs__2.7.3.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.hadoop--hadoop-mapreduce-client-app--org.apache.hadoop__hadoop-mapreduce-client-app__2.7.3.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.hadoop--hadoop-mapreduce-client-common--org.apache.hadoop__hadoop-mapreduce-client-common__2.7.3.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.hadoop--hadoop-mapreduce-client-core--org.apache.hadoop__hadoop-mapreduce-client-core__2.7.3.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.hadoop--hadoop-mapreduce-client-jobclient--org.apache.hadoop__hadoop-mapreduce-client-jobclient__2.7.3.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.hadoop--hadoop-mapreduce-client-shuffle--org.apache.hadoop__hadoop-mapreduce-client-shuffle__2.7.3.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.hadoop--hadoop-yarn-api--org.apache.hadoop__hadoop-yarn-api__2.7.3.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.hadoop--hadoop-yarn-client--org.apache.hadoop__hadoop-yarn-client__2.7.3.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.hadoop--hadoop-yarn-common--org.apache.hadoop__hadoop-yarn-common__2.7.3.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.hadoop--hadoop-yarn-server-common--org.apache.hadoop__hadoop-yarn-server-common__2.7.3.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.htrace--htrace-core--org.apache.htrace__htrace-core__3.1.0-incubating.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.httpcomponents--httpclient--org.apache.httpcomponents__httpclient__4.5.4.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.httpcomponents--httpcore--org.apache.httpcomponents__httpcore__4.4.8.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.ivy--ivy--org.apache.ivy__ivy__2.4.0.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.orc--orc-core-nohive--org.apache.orc__orc-core-nohive__1.4.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.orc--orc-mapreduce-nohive--org.apache.orc__orc-mapreduce-nohive__1.4.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.parquet--parquet-column--org.apache.parquet__parquet-column__1.8.2-databricks1.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.parquet--parquet-common--org.apache.parquet__parquet-common__1.8.2-databricks1.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.parquet--parquet-encoding--org.apache.parquet__parquet-encoding__1.8.2-databricks1.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.parquet--parquet-format--org.apache.parquet__parquet-format__2.3.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.parquet--parquet-hadoop--org.apache.parquet__parquet-hadoop__1.8.2-databricks1.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.parquet--parquet-jackson--org.apache.parquet__parquet-jackson__1.8.2-databricks1.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.thrift--libfb303--org.apache.thrift__libfb303__0.9.3.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.thrift--libthrift--org.apache.thrift__libthrift__0.9.3.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.xbean--xbean-asm5-shaded--org.apache.xbean__xbean-asm5-shaded__4.4.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.apache.zookeeper--zookeeper--org.apache.zookeeper__zookeeper__3.4.6.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.bouncycastle--bcprov-jdk15on--org.bouncycastle__bcprov-jdk15on__1.58.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.codehaus.jackson--jackson-core-asl--org.codehaus.jackson__jackson-core-asl__1.9.13.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.codehaus.jackson--jackson-jaxrs--org.codehaus.jackson__jackson-jaxrs__1.9.13.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.codehaus.jackson--jackson-mapper-asl--org.codehaus.jackson__jackson-mapper-asl__1.9.13.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.codehaus.jackson--jackson-xc--org.codehaus.jackson__jackson-xc__1.9.13.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.codehaus.janino--commons-compiler--org.codehaus.janino__commons-compiler__3.0.8.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.codehaus.janino--janino--org.codehaus.janino__janino__3.0.8.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.datanucleus--datanucleus-api-jdo--org.datanucleus__datanucleus-api-jdo__3.2.6.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.datanucleus--datanucleus-core--org.datanucleus__datanucleus-core__3.2.10.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.datanucleus--datanucleus-rdbms--org.datanucleus__datanucleus-rdbms__3.2.9.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.eclipse.jetty--jetty-client--org.eclipse.jetty__jetty-client__9.3.20.v20170531.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.eclipse.jetty--jetty-continuation--org.eclipse.jetty__jetty-continuation__9.3.20.v20170531.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.eclipse.jetty--jetty-http--org.eclipse.jetty__jetty-http__9.3.20.v20170531.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.eclipse.jetty--jetty-io--org.eclipse.jetty__jetty-io__9.3.20.v20170531.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.eclipse.jetty--jetty-jndi--org.eclipse.jetty__jetty-jndi__9.3.20.v20170531.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.eclipse.jetty--jetty-plus--org.eclipse.jetty__jetty-plus__9.3.20.v20170531.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.eclipse.jetty--jetty-proxy--org.eclipse.jetty__jetty-proxy__9.3.20.v20170531.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.eclipse.jetty--jetty-security--org.eclipse.jetty__jetty-security__9.3.20.v20170531.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.eclipse.jetty--jetty-server--org.eclipse.jetty__jetty-server__9.3.20.v20170531.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.eclipse.jetty--jetty-servlet--org.eclipse.jetty__jetty-servlet__9.3.20.v20170531.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.eclipse.jetty--jetty-servlets--org.eclipse.jetty__jetty-servlets__9.3.20.v20170531.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.eclipse.jetty--jetty-util--org.eclipse.jetty__jetty-util__9.3.20.v20170531.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.eclipse.jetty--jetty-webapp--org.eclipse.jetty__jetty-webapp__9.3.20.v20170531.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.eclipse.jetty--jetty-xml--org.eclipse.jetty__jetty-xml__9.3.20.v20170531.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.fusesource.leveldbjni--leveldbjni-all--org.fusesource.leveldbjni__leveldbjni-all__1.8.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.glassfish.hk2.external--aopalliance-repackaged--org.glassfish.hk2.external__aopalliance-repackaged__2.4.0-b34.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.glassfish.hk2.external--javax.inject--org.glassfish.hk2.external__javax.inject__2.4.0-b34.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.glassfish.hk2--hk2-api--org.glassfish.hk2__hk2-api__2.4.0-b34.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.glassfish.hk2--hk2-locator--org.glassfish.hk2__hk2-locator__2.4.0-b34.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.glassfish.hk2--hk2-utils--org.glassfish.hk2__hk2-utils__2.4.0-b34.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.glassfish.hk2--osgi-resource-locator--org.glassfish.hk2__osgi-resource-locator__1.0.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.glassfish.jersey.bundles.repackaged--jersey-guava--org.glassfish.jersey.bundles.repackaged__jersey-guava__2.22.2.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.glassfish.jersey.containers--jersey-container-servlet-core--org.glassfish.jersey.containers__jersey-container-servlet-core__2.22.2.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.glassfish.jersey.containers--jersey-container-servlet--org.glassfish.jersey.containers__jersey-container-servlet__2.22.2.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.glassfish.jersey.core--jersey-client--org.glassfish.jersey.core__jersey-client__2.22.2.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.glassfish.jersey.core--jersey-common--org.glassfish.jersey.core__jersey-common__2.22.2.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.glassfish.jersey.core--jersey-server--org.glassfish.jersey.core__jersey-server__2.22.2.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.glassfish.jersey.media--jersey-media-jaxb--org.glassfish.jersey.media__jersey-media-jaxb__2.22.2.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.hibernate--hibernate-validator--org.hibernate__hibernate-validator__5.1.1.Final.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.iq80.snappy--snappy--org.iq80.snappy__snappy__0.2.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.javassist--javassist--org.javassist__javassist__3.18.1-GA.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.jboss.logging--jboss-logging--org.jboss.logging__jboss-logging__3.1.3.GA.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.jdbi--jdbi--org.jdbi__jdbi__2.63.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.joda--joda-convert--org.joda__joda-convert__1.7.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.jodd--jodd-core--org.jodd__jodd-core__3.5.2.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.json4s--json4s-ast_2.11--org.json4s__json4s-ast_2.11__3.2.11.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.json4s--json4s-core_2.11--org.json4s__json4s-core_2.11__3.2.11.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.json4s--json4s-jackson_2.11--org.json4s__json4s-jackson_2.11__3.2.11.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.lz4--lz4-java--org.lz4__lz4-java__1.4.0.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.mariadb.jdbc--mariadb-java-client--org.mariadb.jdbc__mariadb-java-client__2.1.2.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.mockito--mockito-all--org.mockito__mockito-all__1.9.5.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.objenesis--objenesis--org.objenesis__objenesis__2.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.postgresql--postgresql--org.postgresql__postgresql__42.1.4.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.roaringbitmap--RoaringBitmap--org.roaringbitmap__RoaringBitmap__0.5.11.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.rocksdb--rocksdbjni--org.rocksdb__rocksdbjni__5.2.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.rosuda.REngine--REngine--org.rosuda.REngine__REngine__2.1.0.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.scalacheck--scalacheck_2.11--org.scalacheck__scalacheck_2.11__1.12.5.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.scala-lang.modules--scala-parser-combinators_2.11--org.scala-lang.modules__scala-parser-combinators_2.11__1.0.2.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.scala-lang.modules--scala-xml_2.11--org.scala-lang.modules__scala-xml_2.11__1.0.5.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.scala-lang--scala-compiler_2.11--org.scala-lang__scala-compiler__2.11.8.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.scala-lang--scala-library_2.11--org.scala-lang__scala-library__2.11.8.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.scala-lang--scalap_2.11--org.scala-lang__scalap__2.11.8.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.scala-lang--scala-reflect_2.11--org.scala-lang__scala-reflect__2.11.8.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.scalanlp--breeze_2.11--org.scalanlp__breeze_2.11__0.13.2.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.scalanlp--breeze-macros_2.11--org.scalanlp__breeze-macros_2.11__0.13.2.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.scala-sbt--test-interface--org.scala-sbt__test-interface__1.0.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.scalatest--scalatest_2.11--org.scalatest__scalatest_2.11__2.2.6.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.slf4j--jcl-over-slf4j--org.slf4j__jcl-over-slf4j__1.7.16.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.slf4j--jul-to-slf4j--org.slf4j__jul-to-slf4j__1.7.16.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.slf4j--slf4j-api--org.slf4j__slf4j-api__1.7.16.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.slf4j--slf4j-log4j12--org.slf4j__slf4j-log4j12__1.7.16.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.spark-project.hive--hive-beeline--org.spark-project.hive__hive-beeline__1.2.1.spark2.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.spark-project.hive--hive-cli--org.spark-project.hive__hive-cli__1.2.1.spark2.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.spark-project.hive--hive-exec--org.spark-project.hive__hive-exec__1.2.1.spark2.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.spark-project.hive--hive-jdbc--org.spark-project.hive__hive-jdbc__1.2.1.spark2.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.spark-project.hive--hive-metastore--org.spark-project.hive__hive-metastore__1.2.1.spark2.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.spark-project.spark--unused--org.spark-project.spark__unused__1.0.0.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.spire-math--spire_2.11--org.spire-math__spire_2.11__0.13.0.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.spire-math--spire-macros_2.11--org.spire-math__spire-macros_2.11__0.13.0.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.springframework--spring-core--org.springframework__spring-core__4.1.4.RELEASE.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.springframework--spring-test--org.springframework__spring-test__4.1.4.RELEASE.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.tukaani--xz--org.tukaani__xz__1.0.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.typelevel--machinist_2.11--org.typelevel__machinist_2.11__0.6.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.typelevel--macro-compat_2.11--org.typelevel__macro-compat_2.11__1.1.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.xerial.snappy--snappy-java--org.xerial.snappy__snappy-java__1.1.2.6.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.xerial--sqlite-jdbc--org.xerial__sqlite-jdbc__3.8.11.2.jar:/databricks/jars/spark--maven-trees--spark_2.3--org.yaml--snakeyaml--org.yaml__snakeyaml__1.16.jar:/databricks/jars/spark--maven-trees--spark_2.3--oro--oro--oro__oro__2.0.8.jar:/databricks/jars/spark--maven-trees--spark_2.3--software.amazon.ion--ion-java--software.amazon.ion__ion-java__1.0.2.jar:/databricks/jars/spark--maven-trees--spark_2.3--stax--stax-api--stax__stax-api__1.0.1.jar:/databricks/jars/spark--maven-trees--spark_2.3--xmlenc--xmlenc--xmlenc__xmlenc__0.52.jar:/databricks/jars/spark--versions--2.3--avro_2.11_deploy.jar:/databricks/jars/spark--versions--2.3--catalyst_2.11_deploy.jar:/databricks/jars/spark--versions--2.3--core_2.11_deploy.jar:/databricks/jars/spark--versions--2.3--ganglia-lgpl_2.11_deploy.jar:/databricks/jars/spark--versions--2.3--graphx_2.11_deploy.jar:/databricks/jars/spark--versions--2.3--hive_2.11_deploy.jar:/databricks/jars/spark--versions--2.3--hive-thriftserver_2.11_deploy.jar:/databricks/jars/spark--versions--2.3--kafka_2.11_only_kafka08_shaded.jar:/databricks/jars/spark--versions--2.3--kafka-clients_only_kafka08_shaded.jar:/databricks/jars/spark--versions--2.3--kafka-clients_only_shaded.jar:/databricks/jars/spark--versions--2.3--libspark-sql-parser-compiled.jar:/databricks/jars/spark--versions--2.3--metrics-core_only_kafka08_shaded.jar:/databricks/jars/spark--versions--2.3--mllib_2.11_deploy_shaded.jar:/databricks/jars/spark--versions--2.3--mllib-local_2.11_deploy.jar:/databricks/jars/spark--versions--2.3--org.jpmml__pmml-model__1.2.15_shaded.jar:/databricks/jars/spark--versions--2.3--org.jpmml__pmml-schema__1.2.15_shaded.jar:/databricks/jars/spark--versions--2.3--py4j_2.11_deploy.jar:/databricks/jars/spark--versions--2.3--redshift_2.11_deploy.jar:/databricks/jars/spark--versions--2.3--repl_2.11_deploy.jar:/databricks/jars/spark--versions--2.3--shim_2.11_deploy.jar:/databricks/jars/spark--versions--2.3--spark_2.11_deploy.jar:/databricks/jars/spark--versions--2.3--spark-2.3-core-resources-jar-resources.jar:/databricks/jars/spark--versions--2.3--spark-2.3-hive-resources-jar-resources.jar:/databricks/jars/spark--versions--2.3--spark-2.3-mllib-resources-jar-resources.jar:/databricks/jars/spark--versions--2.3--spark-2.3-spark-sql-aws-resources-jar-resources.jar:/databricks/jars/spark--versions--2.3--spark-2.3-spark-sql-kafka-0-10-resources-jar-resources.jar:/databricks/jars/spark--versions--2.3--spark-2.3-spark-sql-kafka-0-8-resources-jar-resources.jar:/databricks/jars/spark--versions--2.3--spark-2.3-sql-resources-jar-resources.jar:/databricks/jars/spark--versions--2.3--spark-2.3-streaming-resources-jar-resources.jar:/databricks/jars/spark--versions--2.3--spark-sql-aws_2.11_deploy.jar:/databricks/jars/spark--versions--2.3--spark-sql-kafka-0-10_2.11_deploy_shaded.jar:/databricks/jars/spark--versions--2.3--spark-sql-kafka-0-8_2.11_deploy_shaded.jar:/databricks/jars/spark--versions--2.3--sql_2.11_deploy.jar:/databricks/jars/spark--versions--2.3--sqldw_2.11_deploy.jar:/databricks/jars/spark--versions--2.3--streaming_2.11_deploy.jar:/databricks/jars/spark--versions--2.3--tags_2.11_deploy.jar:/databricks/jars/third_party--azure--com.fasterxml.jackson.core__jackson-core__2.7.2_shaded.jar:/databricks/jars/third_party--azure--com.microsoft.azure__azure-keyvault-core__0.8.0_shaded.jar:/databricks/jars/third_party--azure--com.microsoft.azure__azure-storage__5.2.0_shaded.jar:/databricks/jars/third_party--azure--org.apache.commons__commons-lang3__3.3.1_shaded.jar:/databricks/jars/third_party--datalake--datalake-spark_2.3_2.11_deploy.jar:/databricks/jars/third_party--hadoop-azure--shaded-hadoop-azure-external-spark_2.3_2.11_deploy.jar:/databricks/jars/third_party--jackson--guava_only_shaded.jar:/databricks/jars/third_party--jackson--jackson-module-scala-shaded_2.11_deploy.jar:/databricks/jars/third_party--jackson--jsr305_only_shaded.jar:/databricks/jars/third_party--jackson--paranamer_only_shaded.jar:/databricks/jars/third_party--jetty8-shaded-client--databricks-patched-jetty-jars_shaded.jar:/databricks/jars/third_party--jetty8-shaded-client--jetty-http_shaded.jar:/databricks/jars/third_party--jetty8-shaded-client--jetty-io_shaded.jar:/databricks/jars/third_party--jetty8-shaded-client--jetty-jmx_shaded.jar:/databricks/jars/third_party--jetty8-shaded-client--jetty-util_shaded.jar:/databricks/jars/utils--process_utils_deploy.jar:/databricks/jars/workflow--workflow-spark_2.3_2.11_deploy.jar:/databricks/spark/conf/:/databricks/spark/assembly/target/scala-2.11/jars/*:/databricks/spark/dbconf/log4j/master-worker/" "-Xmx21587M" "-Dspark.ui.port=41292" "-Dspark.driver.port=37583" "-Dspark.hadoop.hive.server2.thrift.http.port=10000" "-Dspark.shuffle.service.port=4048" "-XX:ReservedCodeCacheSize=256m" "-XX:+UseCodeCacheFlushing" "-Ddatabricks.serviceName=spark-executor-1" "-javaagent:/databricks/DatabricksAgent.jar" "-XX:+PrintFlagsFinal" "-XX:+PrintGCDateStamps" "-verbose:gc" "-XX:+PrintGCDetails" "-Xss4m" "-Djavax.xml.datatype.DatatypeFactory=com.sun.org.apache.xerces.internal.jaxp.datatype.DatatypeFactoryImpl" "-Djavax.xml.parsers.DocumentBuilderFactory=com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderFactoryImpl" "-Djavax.xml.parsers.SAXParserFactory=com.sun.org.apache.xerces.internal.jaxp.SAXParserFactoryImpl" "-Djavax.xml.validation.SchemaFactory:http://www.w3.org/2001/XMLSchema=com.sun.org.apache.xerces.internal.jaxp.validation.XMLSchemaFactory" "-Dorg.xml.sax.driver=com.sun.org.apache.xerces.internal.parsers.SAXParser" "-Dorg.w3c.dom.DOMImplementationSourceList=com.sun.org.apache.xerces.internal.dom.DOMXSImplementationSourceImpl" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@ip-10-140-228-59.us-west-2.compute.internal:37583" "--executor-id" "3" "--hostname" "10.140.231.120" "--cores" "8" "--app-id" "app-20180525094813-0000" "--worker-url" "spark://Worker@10.140.231.120:43479"
========================================

18/05/25 09:48:21 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 1807@0524-083453-papas592_10_140_231_120
18/05/25 09:48:21 INFO SignalUtils: Registered signal handler for TERM
18/05/25 09:48:21 INFO SignalUtils: Registered signal handler for HUP
18/05/25 09:48:21 INFO SignalUtils: Registered signal handler for INT
18/05/25 09:48:22 INFO SecurityManager: Changing view acls to: root
18/05/25 09:48:22 INFO SecurityManager: Changing modify acls to: root
18/05/25 09:48:22 INFO SecurityManager: Changing view acls groups to: 
18/05/25 09:48:22 INFO SecurityManager: Changing modify acls groups to: 
18/05/25 09:48:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
18/05/25 09:48:22 INFO TransportClientFactory: Successfully created connection to ip-10-140-228-59.us-west-2.compute.internal/10.140.228.59:37583 after 80 ms (0 ms spent in bootstraps)
18/05/25 09:48:22 WARN SparkConf: The configuration key 'spark.scheduler.listenerbus.eventqueue.size' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.scheduler.listenerbus.eventqueue.capacity' instead.
18/05/25 09:48:22 WARN SparkConf: The configuration key 'spark.akka.frameSize' has been deprecated as of Spark 1.6 and may be removed in the future. Please use the new key 'spark.rpc.message.maxSize' instead.
18/05/25 09:48:22 INFO SecurityManager: Changing view acls to: root
18/05/25 09:48:22 INFO SecurityManager: Changing modify acls to: root
18/05/25 09:48:22 INFO SecurityManager: Changing view acls groups to: 
18/05/25 09:48:22 INFO SecurityManager: Changing modify acls groups to: 
18/05/25 09:48:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
18/05/25 09:48:22 INFO TransportClientFactory: Successfully created connection to ip-10-140-228-59.us-west-2.compute.internal/10.140.228.59:37583 after 1 ms (0 ms spent in bootstraps)
18/05/25 09:48:22 INFO DiskBlockManager: Created local directory at /local_disk0/spark-fa908b1b-c2a1-4429-bc3d-22dd619d0584/executor-c48a079c-15b9-4762-9ba5-e1f75aed47ad/blockmgr-4736fe5f-2ac7-4f8e-8c42-1dc73ef7a3cc
18/05/25 09:48:22 INFO MemoryStore: MemoryStore started with capacity 11.1 GB
18/05/25 09:48:22 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@ip-10-140-228-59.us-west-2.compute.internal:37583
18/05/25 09:48:22 INFO WorkerWatcher: Connecting to worker spark://Worker@10.140.231.120:43479
18/05/25 09:48:22 INFO TransportClientFactory: Successfully created connection to /10.140.231.120:43479 after 2 ms (0 ms spent in bootstraps)
18/05/25 09:48:22 INFO WorkerWatcher: Successfully connected to spark://Worker@10.140.231.120:43479
18/05/25 09:48:22 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
18/05/25 09:48:22 INFO Executor: Starting executor ID 3 on host 10.140.231.120
18/05/25 09:48:22 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40365.
18/05/25 09:48:22 INFO NettyBlockTransferService: Server created on 10.140.231.120:40365
18/05/25 09:48:22 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/05/25 09:48:22 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(3, 10.140.231.120, 40365, None)
18/05/25 09:48:22 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(3, 10.140.231.120, 40365, None)
18/05/25 09:48:22 INFO BlockManager: external shuffle service port = 4048
18/05/25 09:48:22 INFO BlockManager: Registering executor with local external shuffle service.
18/05/25 09:48:22 INFO TransportClientFactory: Successfully created connection to /10.140.231.120:4048 after 1 ms (0 ms spent in bootstraps)
18/05/25 09:48:22 INFO BlockManager: Initialized BlockManager: BlockManagerId(3, 10.140.231.120, 40365, None)
18/05/25 09:48:22 INFO Executor: Using REPL class URI: spark://ip-10-140-228-59.us-west-2.compute.internal:37583/classes
18/05/25 09:49:42 INFO CoarseGrainedExecutorBackend: Got assigned task 5
18/05/25 09:49:42 INFO CoarseGrainedExecutorBackend: Got assigned task 13
18/05/25 09:49:42 INFO CoarseGrainedExecutorBackend: Got assigned task 21
18/05/25 09:49:42 INFO CoarseGrainedExecutorBackend: Got assigned task 29
18/05/25 09:49:42 INFO CoarseGrainedExecutorBackend: Got assigned task 37
18/05/25 09:49:42 INFO CoarseGrainedExecutorBackend: Got assigned task 45
18/05/25 09:49:42 INFO CoarseGrainedExecutorBackend: Got assigned task 53
18/05/25 09:49:42 INFO CoarseGrainedExecutorBackend: Got assigned task 61
18/05/25 09:49:42 INFO Executor: Running task 37.0 in stage 0.0 (TID 37)
18/05/25 09:49:42 INFO Executor: Running task 21.0 in stage 0.0 (TID 21)
18/05/25 09:49:42 INFO Executor: Running task 45.0 in stage 0.0 (TID 45)
18/05/25 09:49:42 INFO Executor: Running task 5.0 in stage 0.0 (TID 5)
18/05/25 09:49:42 INFO Executor: Running task 13.0 in stage 0.0 (TID 13)
18/05/25 09:49:42 INFO Executor: Running task 61.0 in stage 0.0 (TID 61)
18/05/25 09:49:42 INFO Executor: Running task 29.0 in stage 0.0 (TID 29)
18/05/25 09:49:42 INFO Executor: Running task 53.0 in stage 0.0 (TID 53)
18/05/25 09:49:42 INFO TorrentBroadcast: Started reading broadcast variable 1
18/05/25 09:49:42 INFO TransportClientFactory: Successfully created connection to ip-10-140-228-59.us-west-2.compute.internal/10.140.228.59:36837 after 1 ms (0 ms spent in bootstraps)
18/05/25 09:49:42 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.8 KB, free 11.1 GB)
18/05/25 09:49:42 INFO TorrentBroadcast: Reading broadcast variable 1 took 149 ms
18/05/25 09:49:43 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 9.9 KB, free 11.1 GB)
18/05/25 09:49:43 INFO TransportClientFactory: Successfully created connection to ip-10-140-228-59.us-west-2.compute.internal/10.140.228.59:37583 after 1 ms (0 ms spent in bootstraps)
18/05/25 09:49:43 INFO CodeGenerator: Code generated in 280.23636 ms
18/05/25 09:49:43 INFO CodeGenerator: Code generated in 19.871848 ms
18/05/25 09:49:43 INFO TorrentBroadcast: Started reading broadcast variable 0
18/05/25 09:49:43 INFO TransportClientFactory: Successfully created connection to /10.140.250.235:38438 after 1 ms (0 ms spent in bootstraps)
18/05/25 09:49:43 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 42.9 KB, free 11.1 GB)
18/05/25 09:49:43 INFO TorrentBroadcast: Reading broadcast variable 0 took 40 ms
18/05/25 09:49:43 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 515.6 KB, free 11.1 GB)
18/05/25 09:49:44 INFO StaticConf$: DB_HOME: /databricks
18/05/25 09:49:44 INFO DatabricksFileSystemV2Factory: Creating S3A file system for s3a://pstuedi
18/05/25 09:49:44 INFO DatabricksFileSystemV2Factory: Creating S3A file system for s3a://pstuedi
18/05/25 09:49:44 INFO DatabricksFileSystemV2Factory: Creating S3A file system for s3a://pstuedi
18/05/25 09:49:44 INFO DatabricksFileSystemV2Factory: Creating S3A file system for s3a://pstuedi
18/05/25 09:49:44 INFO DatabricksFileSystemV2Factory: Creating S3A file system for s3a://pstuedi
18/05/25 09:49:44 INFO DatabricksFileSystemV2Factory: Creating S3A file system for s3a://pstuedi
18/05/25 09:49:44 INFO DatabricksFileSystemV2Factory: Creating S3A file system for s3a://pstuedi
18/05/25 09:49:44 INFO DatabricksFileSystemV2Factory: Creating S3A file system for s3a://pstuedi
18/05/25 09:49:46 INFO DBFS: Initialized DBFS with DBFSV2 as the delegate.
18/05/25 09:49:46 INFO DBFS: Initialized DBFS with DBFSV2 as the delegate.
18/05/25 09:49:46 INFO DBFS: Initialized DBFS with DBFSV2 as the delegate.
18/05/25 09:49:46 INFO DBFS: Initialized DBFS with DBFSV2 as the delegate.
18/05/25 09:49:46 INFO DBFS: Initialized DBFS with DBFSV2 as the delegate.
18/05/25 09:49:46 INFO DBFS: Initialized DBFS with DBFSV2 as the delegate.
18/05/25 09:49:46 INFO DBFS: Initialized DBFS with DBFSV2 as the delegate.
18/05/25 09:49:46 INFO DBFS: Initialized DBFS with DBFSV2 as the delegate.
18/05/25 09:49:47 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00029-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-552-c000.avro, range: 0-134217728, partition values: [empty row].
18/05/25 09:49:47 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00013-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-536-c000.avro, range: 0-134217728, partition values: [empty row].
18/05/25 09:49:47 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00061-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-584-c000.avro, range: 0-134217728, partition values: [empty row].
18/05/25 09:49:47 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00045-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-568-c000.avro, range: 0-134217728, partition values: [empty row].
18/05/25 09:49:47 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00005-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-528-c000.avro, range: 0-134217728, partition values: [empty row].
18/05/25 09:49:47 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00021-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-544-c000.avro, range: 0-134217728, partition values: [empty row].
18/05/25 09:49:47 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00037-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-560-c000.avro, range: 0-134217728, partition values: [empty row].
18/05/25 09:49:47 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00053-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-576-c000.avro, range: 0-134217728, partition values: [empty row].
18/05/25 09:49:48 INFO CodeGenerator: Code generated in 36.416153 ms
18/05/25 09:49:54 WARN ThrottledLogger$: Failed to load user identity when calling dbfs, missing userId,orgId,user.
java.lang.Exception: Get stack trace for missing UserIdentity
	at com.databricks.backend.daemon.data.client.DbfsClient$$anonfun$doSend$2.apply(DbfsClient.scala:128)
	at com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:188)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:183)
	at com.databricks.backend.daemon.data.client.DbfsClient.withAttributionContext(DbfsClient.scala:19)
	at com.databricks.logging.UsageLogging$class.withAttributionTags(UsageLogging.scala:221)
	at com.databricks.backend.daemon.data.client.DbfsClient.withAttributionTags(DbfsClient.scala:19)
	at com.databricks.backend.daemon.data.client.DbfsClient.doSend(DbfsClient.scala:123)
	at com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:84)
	at com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:55)
	at com.databricks.backend.daemon.data.client.DatabricksMountsStore.com$databricks$backend$daemon$data$client$DatabricksMountsStore$$refreshMounts(DatabricksMountsStore.scala:72)
	at com.databricks.backend.daemon.data.client.DatabricksMountsStore$$anonfun$1.apply(DatabricksMountsStore.scala:65)
	at com.databricks.backend.daemon.data.client.DatabricksMountsStore$$anonfun$1.apply(DatabricksMountsStore.scala:65)
	at com.databricks.logging.UsageLogging$$anonfun$recordOperation$1.apply(UsageLogging.scala:313)
	at com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:188)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:183)
	at com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:305)
	at com.databricks.logging.UsageLogging$class.withAttributionTags(UsageLogging.scala:221)
	at com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionTags(SingletonJob.scala:305)
	at com.databricks.logging.UsageLogging$class.recordOperation(UsageLogging.scala:298)
	at com.databricks.threading.SingletonJob$SingletonJobImpl.recordOperation(SingletonJob.scala:305)
	at com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun$$anonfun$2$$anonfun$apply$1.apply(SingletonJob.scala:354)
	at com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:188)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:183)
	at com.databricks.threading.SingletonJob$SingletonJobImpl.withAttributionContext(SingletonJob.scala:305)
	at com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun$$anonfun$2.apply(SingletonJob.scala:353)
	at scala.util.Try$.apply(Try.scala:192)
	at com.databricks.threading.SingletonJob$SingletonJobImpl$SingletonRun.run(SingletonJob.scala:352)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
18/05/25 09:49:57 INFO Executor: Finished task 13.0 in stage 0.0 (TID 13). 57110 bytes result sent to driver
18/05/25 09:49:57 INFO CoarseGrainedExecutorBackend: Got assigned task 65
18/05/25 09:49:57 INFO Executor: Running task 65.0 in stage 0.0 (TID 65)
18/05/25 09:49:57 INFO Executor: Finished task 53.0 in stage 0.0 (TID 53). 57110 bytes result sent to driver
18/05/25 09:49:57 INFO CoarseGrainedExecutorBackend: Got assigned task 71
18/05/25 09:49:57 INFO Executor: Running task 71.0 in stage 0.0 (TID 71)
18/05/25 09:49:57 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00065-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-588-c000.avro, range: 0-134217728, partition values: [empty row].
18/05/25 09:49:57 INFO Executor: Finished task 45.0 in stage 0.0 (TID 45). 57110 bytes result sent to driver
18/05/25 09:49:57 INFO CoarseGrainedExecutorBackend: Got assigned task 76
18/05/25 09:49:58 INFO Executor: Running task 76.0 in stage 0.0 (TID 76)
18/05/25 09:49:58 INFO Executor: Finished task 61.0 in stage 0.0 (TID 61). 57110 bytes result sent to driver
18/05/25 09:49:58 INFO CoarseGrainedExecutorBackend: Got assigned task 85
18/05/25 09:49:58 INFO Executor: Running task 85.0 in stage 0.0 (TID 85)
18/05/25 09:49:58 INFO Executor: Finished task 21.0 in stage 0.0 (TID 21). 57110 bytes result sent to driver
18/05/25 09:49:58 INFO CoarseGrainedExecutorBackend: Got assigned task 87
18/05/25 09:49:58 INFO Executor: Running task 87.0 in stage 0.0 (TID 87)
18/05/25 09:49:58 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00071-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-594-c000.avro, range: 0-134217728, partition values: [empty row].
18/05/25 09:49:58 INFO Executor: Finished task 37.0 in stage 0.0 (TID 37). 57110 bytes result sent to driver
18/05/25 09:49:58 INFO CoarseGrainedExecutorBackend: Got assigned task 94
18/05/25 09:49:58 INFO Executor: Running task 94.0 in stage 0.0 (TID 94)
18/05/25 09:49:58 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00076-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-599-c000.avro, range: 0-134217728, partition values: [empty row].
18/05/25 09:49:58 INFO Executor: Finished task 5.0 in stage 0.0 (TID 5). 57067 bytes result sent to driver
18/05/25 09:49:58 INFO CoarseGrainedExecutorBackend: Got assigned task 102
18/05/25 09:49:58 INFO Executor: Running task 102.0 in stage 0.0 (TID 102)
18/05/25 09:49:58 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00094-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-617-c000.avro, range: 0-134217728, partition values: [empty row].
18/05/25 09:49:58 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00087-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-610-c000.avro, range: 0-134217728, partition values: [empty row].
18/05/25 09:49:58 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00061-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-584-c000.avro, range: 134217728-190112989, partition values: [empty row].
18/05/25 09:49:58 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00085-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-608-c000.avro, range: 0-134217728, partition values: [empty row].
18/05/25 09:49:58 INFO Executor: Finished task 29.0 in stage 0.0 (TID 29). 57110 bytes result sent to driver
18/05/25 09:49:58 INFO CoarseGrainedExecutorBackend: Got assigned task 111
18/05/25 09:49:58 INFO Executor: Running task 111.0 in stage 0.0 (TID 111)
18/05/25 09:49:58 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00042-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-565-c000.avro, range: 134217728-190110589, partition values: [empty row].
18/05/25 09:50:02 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00079-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-602-c000.avro, range: 134217728-190112778, partition values: [empty row].
18/05/25 09:50:03 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00037-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-560-c000.avro, range: 134217728-190110457, partition values: [empty row].
18/05/25 09:50:06 INFO Executor: Finished task 102.0 in stage 0.0 (TID 102). 57110 bytes result sent to driver
18/05/25 09:50:06 INFO CoarseGrainedExecutorBackend: Got assigned task 130
18/05/25 09:50:06 INFO Executor: Running task 130.0 in stage 0.0 (TID 130)
18/05/25 09:50:06 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00074-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-597-c000.avro, range: 134217728-190108662, partition values: [empty row].
18/05/25 09:50:07 INFO Executor: Finished task 65.0 in stage 0.0 (TID 65). 57110 bytes result sent to driver
18/05/25 09:50:07 INFO CoarseGrainedExecutorBackend: Got assigned task 139
18/05/25 09:50:07 INFO Executor: Running task 139.0 in stage 0.0 (TID 139)
18/05/25 09:50:07 INFO Executor: Finished task 111.0 in stage 0.0 (TID 111). 57110 bytes result sent to driver
18/05/25 09:50:07 INFO CoarseGrainedExecutorBackend: Got assigned task 146
18/05/25 09:50:07 INFO Executor: Running task 146.0 in stage 0.0 (TID 146)
18/05/25 09:50:07 INFO Executor: Finished task 94.0 in stage 0.0 (TID 94). 57067 bytes result sent to driver
18/05/25 09:50:07 INFO Executor: Finished task 76.0 in stage 0.0 (TID 76). 57110 bytes result sent to driver
18/05/25 09:50:07 INFO Executor: Finished task 87.0 in stage 0.0 (TID 87). 57067 bytes result sent to driver
18/05/25 09:50:07 INFO Executor: Finished task 71.0 in stage 0.0 (TID 71). 57110 bytes result sent to driver
18/05/25 09:50:07 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00078-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-601-c000.avro, range: 134217728-190105690, partition values: [empty row].
18/05/25 09:50:07 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00031-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-554-c000.avro, range: 134217728-190107604, partition values: [empty row].
18/05/25 09:50:07 INFO Executor: Finished task 85.0 in stage 0.0 (TID 85). 57110 bytes result sent to driver
18/05/25 09:50:09 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00025-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-548-c000.avro, range: 134217728-190108659, partition values: [empty row].
18/05/25 09:50:10 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00004-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-527-c000.avro, range: 134217728-190107599, partition values: [empty row].
18/05/25 09:50:10 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00013-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-536-c000.avro, range: 134217728-190105410, partition values: [empty row].
18/05/25 09:50:12 INFO Executor: Finished task 130.0 in stage 0.0 (TID 130). 57067 bytes result sent to driver
18/05/25 09:50:12 INFO Executor: Finished task 146.0 in stage 0.0 (TID 146). 57110 bytes result sent to driver
18/05/25 09:50:13 INFO Executor: Finished task 139.0 in stage 0.0 (TID 139). 57067 bytes result sent to driver
18/05/25 09:50:13 INFO CoarseGrainedExecutorBackend: Got assigned task 156
18/05/25 09:50:13 INFO Executor: Running task 6.0 in stage 1.0 (TID 156)
18/05/25 09:50:13 INFO CoarseGrainedExecutorBackend: Got assigned task 164
18/05/25 09:50:13 INFO Executor: Running task 14.0 in stage 1.0 (TID 164)
18/05/25 09:50:13 INFO CoarseGrainedExecutorBackend: Got assigned task 172
18/05/25 09:50:13 INFO Executor: Running task 22.0 in stage 1.0 (TID 172)
18/05/25 09:50:13 INFO CoarseGrainedExecutorBackend: Got assigned task 180
18/05/25 09:50:13 INFO Executor: Running task 30.0 in stage 1.0 (TID 180)
18/05/25 09:50:13 INFO CoarseGrainedExecutorBackend: Got assigned task 188
18/05/25 09:50:13 INFO Executor: Running task 38.0 in stage 1.0 (TID 188)
18/05/25 09:50:13 INFO CoarseGrainedExecutorBackend: Got assigned task 196
18/05/25 09:50:13 INFO Executor: Running task 46.0 in stage 1.0 (TID 196)
18/05/25 09:50:13 INFO CoarseGrainedExecutorBackend: Got assigned task 204
18/05/25 09:50:13 INFO Executor: Running task 54.0 in stage 1.0 (TID 204)
18/05/25 09:50:13 INFO CoarseGrainedExecutorBackend: Got assigned task 212
18/05/25 09:50:13 INFO Executor: Running task 62.0 in stage 1.0 (TID 212)
18/05/25 09:50:13 INFO TorrentBroadcast: Started reading broadcast variable 2
18/05/25 09:50:13 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 12.7 KB, free 11.1 GB)
18/05/25 09:50:13 INFO TorrentBroadcast: Reading broadcast variable 2 took 11 ms
18/05/25 09:50:13 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 38.6 KB, free 11.1 GB)
18/05/25 09:50:13 INFO CodeGenerator: Code generated in 16.054949 ms
18/05/25 09:50:13 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00054-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-577-c000.avro, range: 0-134217728, partition values: [empty row].
18/05/25 09:50:13 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00046-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-569-c000.avro, range: 0-134217728, partition values: [empty row].
18/05/25 09:50:13 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00038-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-561-c000.avro, range: 0-134217728, partition values: [empty row].
18/05/25 09:50:13 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00022-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-545-c000.avro, range: 0-134217728, partition values: [empty row].
18/05/25 09:50:13 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00030-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-553-c000.avro, range: 0-134217728, partition values: [empty row].
18/05/25 09:50:14 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00006-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-529-c000.avro, range: 0-134217728, partition values: [empty row].
18/05/25 09:50:14 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00014-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-537-c000.avro, range: 0-134217728, partition values: [empty row].
18/05/25 09:50:14 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00062-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-585-c000.avro, range: 0-134217728, partition values: [empty row].
18/05/25 09:50:28 INFO Executor: Finished task 46.0 in stage 1.0 (TID 196). 2137 bytes result sent to driver
18/05/25 09:50:28 INFO CoarseGrainedExecutorBackend: Got assigned task 214
18/05/25 09:50:28 INFO Executor: Running task 64.0 in stage 1.0 (TID 214)
18/05/25 09:50:28 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00064-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-587-c000.avro, range: 0-134217728, partition values: [empty row].
18/05/25 09:50:28 INFO Executor: Finished task 38.0 in stage 1.0 (TID 188). 2094 bytes result sent to driver
18/05/25 09:50:28 INFO CoarseGrainedExecutorBackend: Got assigned task 217
18/05/25 09:50:28 INFO Executor: Running task 67.0 in stage 1.0 (TID 217)
18/05/25 09:50:28 INFO Executor: Finished task 22.0 in stage 1.0 (TID 172). 2094 bytes result sent to driver
18/05/25 09:50:28 INFO CoarseGrainedExecutorBackend: Got assigned task 219
18/05/25 09:50:28 INFO Executor: Running task 69.0 in stage 1.0 (TID 219)
18/05/25 09:50:29 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00067-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-590-c000.avro, range: 0-134217728, partition values: [empty row].
18/05/25 09:50:29 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00069-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-592-c000.avro, range: 0-134217728, partition values: [empty row].
18/05/25 09:50:29 INFO Executor: Finished task 54.0 in stage 1.0 (TID 204). 2094 bytes result sent to driver
18/05/25 09:50:29 INFO CoarseGrainedExecutorBackend: Got assigned task 225
18/05/25 09:50:29 INFO Executor: Running task 75.0 in stage 1.0 (TID 225)
18/05/25 09:50:29 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00075-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-598-c000.avro, range: 0-134217728, partition values: [empty row].
18/05/25 09:50:29 INFO Executor: Finished task 30.0 in stage 1.0 (TID 180). 2137 bytes result sent to driver
18/05/25 09:50:29 INFO CoarseGrainedExecutorBackend: Got assigned task 238
18/05/25 09:50:29 INFO Executor: Running task 88.0 in stage 1.0 (TID 238)
18/05/25 09:50:29 INFO Executor: Finished task 6.0 in stage 1.0 (TID 156). 2094 bytes result sent to driver
18/05/25 09:50:29 INFO CoarseGrainedExecutorBackend: Got assigned task 246
18/05/25 09:50:29 INFO Executor: Running task 96.0 in stage 1.0 (TID 246)
18/05/25 09:50:29 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00088-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-611-c000.avro, range: 0-134217728, partition values: [empty row].
18/05/25 09:50:30 INFO Executor: Finished task 62.0 in stage 1.0 (TID 212). 2094 bytes result sent to driver
18/05/25 09:50:30 INFO CoarseGrainedExecutorBackend: Got assigned task 260
18/05/25 09:50:30 INFO Executor: Running task 110.0 in stage 1.0 (TID 260)
18/05/25 09:50:30 INFO Executor: Finished task 14.0 in stage 1.0 (TID 164). 2094 bytes result sent to driver
18/05/25 09:50:30 INFO CoarseGrainedExecutorBackend: Got assigned task 263
18/05/25 09:50:30 INFO Executor: Running task 113.0 in stage 1.0 (TID 263)
18/05/25 09:50:30 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00056-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-579-c000.avro, range: 134217728-190110690, partition values: [empty row].
18/05/25 09:50:30 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00096-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-619-c000.avro, range: 0-134217728, partition values: [empty row].
18/05/25 09:50:30 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00092-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-615-c000.avro, range: 134217728-190110373, partition values: [empty row].
18/05/25 09:50:36 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00002-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-525-c000.avro, range: 134217728-190110632, partition values: [empty row].
18/05/25 09:50:37 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00003-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-526-c000.avro, range: 134217728-190110333, partition values: [empty row].
18/05/25 09:50:43 INFO Executor: Finished task 110.0 in stage 1.0 (TID 260). 2094 bytes result sent to driver
18/05/25 09:50:43 INFO CoarseGrainedExecutorBackend: Got assigned task 288
18/05/25 09:50:43 INFO Executor: Running task 138.0 in stage 1.0 (TID 288)
18/05/25 09:50:43 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00080-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-603-c000.avro, range: 134217728-190107659, partition values: [empty row].
18/05/25 09:50:43 INFO Executor: Finished task 113.0 in stage 1.0 (TID 263). 2094 bytes result sent to driver
18/05/25 09:50:43 INFO CoarseGrainedExecutorBackend: Got assigned task 292
18/05/25 09:50:43 INFO Executor: Running task 142.0 in stage 1.0 (TID 292)
18/05/25 09:50:44 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00072-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-595-c000.avro, range: 134217728-190107170, partition values: [empty row].
18/05/25 09:50:44 INFO Executor: Finished task 75.0 in stage 1.0 (TID 225). 2094 bytes result sent to driver
18/05/25 09:50:44 INFO Executor: Finished task 64.0 in stage 1.0 (TID 214). 2094 bytes result sent to driver
18/05/25 09:50:44 INFO Executor: Finished task 69.0 in stage 1.0 (TID 219). 2094 bytes result sent to driver
18/05/25 09:50:44 INFO Executor: Finished task 67.0 in stage 1.0 (TID 217). 2094 bytes result sent to driver
18/05/25 09:50:45 INFO Executor: Finished task 96.0 in stage 1.0 (TID 246). 2094 bytes result sent to driver
18/05/25 09:50:45 INFO Executor: Finished task 88.0 in stage 1.0 (TID 238). 2094 bytes result sent to driver
18/05/25 09:50:48 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00064-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-587-c000.avro, range: 134217728-190107635, partition values: [empty row].
18/05/25 09:50:48 INFO FileScanRDD: Reading File path: dbfs:/tmp/input-100g/part-00097-tid-1619450849631970524-f2b69cfa-a051-4e92-8505-38360bc202d6-620-c000.avro, range: 134217728-190107058, partition values: [empty row].
18/05/25 09:50:51 INFO Executor: Finished task 138.0 in stage 1.0 (TID 288). 2094 bytes result sent to driver
18/05/25 09:50:52 INFO Executor: Finished task 142.0 in stage 1.0 (TID 292). 2094 bytes result sent to driver
18/05/25 09:50:54 INFO CoarseGrainedExecutorBackend: Got assigned task 301
18/05/25 09:50:54 INFO CoarseGrainedExecutorBackend: Got assigned task 309
18/05/25 09:50:54 INFO Executor: Running task 1.0 in stage 2.0 (TID 301)
18/05/25 09:50:54 INFO Executor: Running task 9.0 in stage 2.0 (TID 309)
18/05/25 09:50:54 INFO CoarseGrainedExecutorBackend: Got assigned task 317
18/05/25 09:50:54 INFO Executor: Running task 17.0 in stage 2.0 (TID 317)
18/05/25 09:50:54 INFO CoarseGrainedExecutorBackend: Got assigned task 325
18/05/25 09:50:54 INFO CoarseGrainedExecutorBackend: Got assigned task 333
18/05/25 09:50:54 INFO Executor: Running task 25.0 in stage 2.0 (TID 325)
18/05/25 09:50:54 INFO Executor: Running task 33.0 in stage 2.0 (TID 333)
18/05/25 09:50:54 INFO MapOutputTrackerWorker: Updating epoch to 1 and clearing cache
18/05/25 09:50:54 INFO CoarseGrainedExecutorBackend: Got assigned task 341
18/05/25 09:50:54 INFO CoarseGrainedExecutorBackend: Got assigned task 349
18/05/25 09:50:54 INFO Executor: Running task 41.0 in stage 2.0 (TID 341)
18/05/25 09:50:54 INFO Executor: Running task 49.0 in stage 2.0 (TID 349)
18/05/25 09:50:54 INFO CoarseGrainedExecutorBackend: Got assigned task 357
18/05/25 09:50:54 INFO TorrentBroadcast: Started reading broadcast variable 3
18/05/25 09:50:54 INFO Executor: Running task 57.0 in stage 2.0 (TID 357)
18/05/25 09:50:54 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 94.4 KB, free 11.1 GB)
18/05/25 09:50:54 INFO TorrentBroadcast: Reading broadcast variable 3 took 9 ms
18/05/25 09:50:54 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 284.3 KB, free 11.1 GB)
18/05/25 09:50:55 INFO deprecation: mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress
18/05/25 09:50:55 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
18/05/25 09:50:55 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@ip-10-140-228-59.us-west-2.compute.internal:37583)
18/05/25 09:50:55 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
18/05/25 09:50:55 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
18/05/25 09:50:55 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
18/05/25 09:50:55 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
18/05/25 09:50:55 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
18/05/25 09:50:55 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
18/05/25 09:50:55 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
18/05/25 09:50:55 INFO MapOutputTrackerWorker: Got the output locations
18/05/25 09:50:55 INFO ShuffleBlockFetcherIterator: Getting 150 non-empty blocks out of 150 blocks
18/05/25 09:50:55 INFO ShuffleBlockFetcherIterator: Getting 150 non-empty blocks out of 150 blocks
18/05/25 09:50:55 INFO ShuffleBlockFetcherIterator: Getting 150 non-empty blocks out of 150 blocks
18/05/25 09:50:55 INFO ShuffleBlockFetcherIterator: Getting 150 non-empty blocks out of 150 blocks
18/05/25 09:50:55 INFO ShuffleBlockFetcherIterator: Getting 150 non-empty blocks out of 150 blocks
18/05/25 09:50:55 INFO ShuffleBlockFetcherIterator: Getting 150 non-empty blocks out of 150 blocks
18/05/25 09:50:55 INFO ShuffleBlockFetcherIterator: Getting 150 non-empty blocks out of 150 blocks
18/05/25 09:50:55 INFO ShuffleBlockFetcherIterator: Getting 150 non-empty blocks out of 150 blocks
18/05/25 09:50:55 INFO TransportClientFactory: Successfully created connection to /10.140.240.74:4048 after 1 ms (0 ms spent in bootstraps)
18/05/25 09:50:55 INFO TransportClientFactory: Successfully created connection to /10.140.234.9:4048 after 6 ms (0 ms spent in bootstraps)
18/05/25 09:50:55 INFO TransportClientFactory: Successfully created connection to /10.140.250.235:4048 after 6 ms (0 ms spent in bootstraps)
18/05/25 09:50:55 INFO TransportClientFactory: Successfully created connection to /10.140.236.89:4048 after 6 ms (0 ms spent in bootstraps)
18/05/25 09:50:55 INFO TransportClientFactory: Successfully created connection to /10.140.231.77:4048 after 10 ms (0 ms spent in bootstraps)
18/05/25 09:50:55 INFO ShuffleBlockFetcherIterator: Started 4 remote fetches in 40 ms
18/05/25 09:50:55 INFO TransportClientFactory: Successfully created connection to /10.140.234.153:4048 after 14 ms (0 ms spent in bootstraps)
18/05/25 09:50:55 INFO ShuffleBlockFetcherIterator: Started 5 remote fetches in 43 ms
18/05/25 09:50:55 INFO TransportClientFactory: Successfully created connection to /10.140.226.148:4048 after 22 ms (0 ms spent in bootstraps)
18/05/25 09:50:55 INFO ShuffleBlockFetcherIterator: Started 4 remote fetches in 44 ms
18/05/25 09:50:55 INFO ShuffleBlockFetcherIterator: Started 4 remote fetches in 45 ms
18/05/25 09:50:55 INFO ShuffleBlockFetcherIterator: Started 5 remote fetches in 44 ms
18/05/25 09:50:55 INFO ShuffleBlockFetcherIterator: Started 5 remote fetches in 52 ms
18/05/25 09:50:55 INFO ShuffleBlockFetcherIterator: Started 6 remote fetches in 79 ms
18/05/25 09:50:55 INFO ShuffleBlockFetcherIterator: Started 6 remote fetches in 88 ms
18/05/25 09:50:55 INFO CodeGenerator: Code generated in 39.900013 ms
18/05/25 09:50:55 INFO CodeGenerator: Code generated in 31.77677 ms
18/05/25 09:51:18 INFO Executor: Finished task 9.0 in stage 2.0 (TID 309). 4137 bytes result sent to driver
18/05/25 09:51:18 INFO CoarseGrainedExecutorBackend: Got assigned task 365
18/05/25 09:51:18 INFO Executor: Running task 65.0 in stage 2.0 (TID 365)
18/05/25 09:51:18 INFO ShuffleBlockFetcherIterator: Getting 150 non-empty blocks out of 150 blocks
18/05/25 09:51:18 INFO ShuffleBlockFetcherIterator: Started 6 remote fetches in 1 ms
18/05/25 09:51:20 INFO Executor: Finished task 33.0 in stage 2.0 (TID 333). 4094 bytes result sent to driver
18/05/25 09:51:20 INFO CoarseGrainedExecutorBackend: Got assigned task 371
18/05/25 09:51:20 INFO Executor: Running task 71.0 in stage 2.0 (TID 371)
18/05/25 09:51:20 INFO ShuffleBlockFetcherIterator: Getting 150 non-empty blocks out of 150 blocks
18/05/25 09:51:20 INFO ShuffleBlockFetcherIterator: Started 5 remote fetches in 1 ms
18/05/25 09:51:25 INFO Executor: Finished task 1.0 in stage 2.0 (TID 301). 4094 bytes result sent to driver
18/05/25 09:51:25 INFO CoarseGrainedExecutorBackend: Got assigned task 392
18/05/25 09:51:25 INFO Executor: Running task 92.0 in stage 2.0 (TID 392)
18/05/25 09:51:25 INFO ShuffleBlockFetcherIterator: Getting 150 non-empty blocks out of 150 blocks
18/05/25 09:51:25 INFO ShuffleBlockFetcherIterator: Started 5 remote fetches in 2 ms
18/05/25 09:51:28 INFO Executor: Finished task 57.0 in stage 2.0 (TID 357). 4094 bytes result sent to driver
18/05/25 09:51:28 INFO CoarseGrainedExecutorBackend: Got assigned task 405
18/05/25 09:51:28 INFO Executor: Running task 105.0 in stage 2.0 (TID 405)
18/05/25 09:51:28 INFO ShuffleBlockFetcherIterator: Getting 150 non-empty blocks out of 150 blocks
18/05/25 09:51:28 INFO ShuffleBlockFetcherIterator: Started 4 remote fetches in 7 ms
18/05/25 09:51:30 INFO Executor: Finished task 17.0 in stage 2.0 (TID 317). 4094 bytes result sent to driver
18/05/25 09:51:30 INFO CoarseGrainedExecutorBackend: Got assigned task 415
18/05/25 09:51:30 INFO Executor: Running task 115.0 in stage 2.0 (TID 415)
18/05/25 09:51:30 INFO ShuffleBlockFetcherIterator: Getting 150 non-empty blocks out of 150 blocks
18/05/25 09:51:30 INFO ShuffleBlockFetcherIterator: Started 5 remote fetches in 2 ms
18/05/25 09:51:30 INFO Executor: Finished task 41.0 in stage 2.0 (TID 341). 4094 bytes result sent to driver
18/05/25 09:51:30 INFO CoarseGrainedExecutorBackend: Got assigned task 416
18/05/25 09:51:30 INFO Executor: Running task 116.0 in stage 2.0 (TID 416)
18/05/25 09:51:30 INFO ShuffleBlockFetcherIterator: Getting 150 non-empty blocks out of 150 blocks
18/05/25 09:51:30 INFO ShuffleBlockFetcherIterator: Started 5 remote fetches in 10 ms
18/05/25 09:51:30 INFO Executor: Finished task 49.0 in stage 2.0 (TID 349). 4094 bytes result sent to driver
18/05/25 09:51:30 INFO CoarseGrainedExecutorBackend: Got assigned task 418
18/05/25 09:51:30 INFO Executor: Running task 118.0 in stage 2.0 (TID 418)
18/05/25 09:51:30 INFO ShuffleBlockFetcherIterator: Getting 150 non-empty blocks out of 150 blocks
18/05/25 09:51:30 INFO ShuffleBlockFetcherIterator: Started 5 remote fetches in 13 ms
18/05/25 09:51:30 INFO Executor: Finished task 25.0 in stage 2.0 (TID 325). 4094 bytes result sent to driver
18/05/25 09:51:30 INFO CoarseGrainedExecutorBackend: Got assigned task 420
18/05/25 09:51:30 INFO Executor: Running task 120.0 in stage 2.0 (TID 420)
18/05/25 09:51:30 INFO ShuffleBlockFetcherIterator: Getting 150 non-empty blocks out of 150 blocks
18/05/25 09:51:30 INFO ShuffleBlockFetcherIterator: Started 5 remote fetches in 2 ms
18/05/25 09:51:31 INFO Executor: Finished task 65.0 in stage 2.0 (TID 365). 4094 bytes result sent to driver
18/05/25 09:51:31 INFO CoarseGrainedExecutorBackend: Got assigned task 421
18/05/25 09:51:31 INFO Executor: Running task 121.0 in stage 2.0 (TID 421)
18/05/25 09:51:31 INFO ShuffleBlockFetcherIterator: Getting 150 non-empty blocks out of 150 blocks
18/05/25 09:51:31 INFO ShuffleBlockFetcherIterator: Started 6 remote fetches in 31 ms
18/05/25 09:51:35 INFO Executor: Finished task 71.0 in stage 2.0 (TID 371). 4094 bytes result sent to driver
18/05/25 09:51:35 INFO CoarseGrainedExecutorBackend: Got assigned task 432
18/05/25 09:51:35 INFO Executor: Running task 132.0 in stage 2.0 (TID 432)
18/05/25 09:51:35 INFO ShuffleBlockFetcherIterator: Getting 150 non-empty blocks out of 150 blocks
18/05/25 09:51:35 INFO ShuffleBlockFetcherIterator: Started 4 remote fetches in 2 ms
18/05/25 09:51:41 INFO Executor: Finished task 92.0 in stage 2.0 (TID 392). 4094 bytes result sent to driver
18/05/25 09:51:41 INFO CoarseGrainedExecutorBackend: Got assigned task 450
18/05/25 09:51:41 INFO Executor: Running task 150.0 in stage 2.0 (TID 450)
18/05/25 09:51:41 INFO ShuffleBlockFetcherIterator: Getting 150 non-empty blocks out of 150 blocks
18/05/25 09:51:41 INFO ShuffleBlockFetcherIterator: Started 4 remote fetches in 31 ms
18/05/25 09:51:46 INFO Executor: Finished task 105.0 in stage 2.0 (TID 405). 4094 bytes result sent to driver
18/05/25 09:51:46 INFO CoarseGrainedExecutorBackend: Got assigned task 472
18/05/25 09:51:46 INFO Executor: Running task 172.0 in stage 2.0 (TID 472)
18/05/25 09:51:46 INFO ShuffleBlockFetcherIterator: Getting 150 non-empty blocks out of 150 blocks
18/05/25 09:51:46 INFO ShuffleBlockFetcherIterator: Started 5 remote fetches in 3 ms
18/05/25 09:51:48 INFO Executor: Finished task 120.0 in stage 2.0 (TID 420). 4094 bytes result sent to driver
18/05/25 09:51:48 INFO CoarseGrainedExecutorBackend: Got assigned task 479
18/05/25 09:51:48 INFO Executor: Running task 179.0 in stage 2.0 (TID 479)
18/05/25 09:51:48 INFO ShuffleBlockFetcherIterator: Getting 150 non-empty blocks out of 150 blocks
18/05/25 09:51:48 INFO ShuffleBlockFetcherIterator: Started 4 remote fetches in 1 ms
18/05/25 09:51:49 INFO Executor: Finished task 121.0 in stage 2.0 (TID 421). 4094 bytes result sent to driver
18/05/25 09:51:49 INFO CoarseGrainedExecutorBackend: Got assigned task 481
18/05/25 09:51:49 INFO Executor: Running task 181.0 in stage 2.0 (TID 481)
18/05/25 09:51:49 INFO ShuffleBlockFetcherIterator: Getting 150 non-empty blocks out of 150 blocks
18/05/25 09:51:49 INFO ShuffleBlockFetcherIterator: Started 5 remote fetches in 1 ms
18/05/25 09:51:50 INFO Executor: Finished task 115.0 in stage 2.0 (TID 415). 4094 bytes result sent to driver
18/05/25 09:51:50 INFO CoarseGrainedExecutorBackend: Got assigned task 487
18/05/25 09:51:50 INFO Executor: Running task 187.0 in stage 2.0 (TID 487)
18/05/25 09:51:50 INFO ShuffleBlockFetcherIterator: Getting 150 non-empty blocks out of 150 blocks
18/05/25 09:51:50 INFO ShuffleBlockFetcherIterator: Started 5 remote fetches in 1 ms
18/05/25 09:51:51 INFO Executor: Finished task 118.0 in stage 2.0 (TID 418). 4137 bytes result sent to driver
18/05/25 09:51:51 INFO CoarseGrainedExecutorBackend: Got assigned task 490
18/05/25 09:51:51 INFO Executor: Running task 190.0 in stage 2.0 (TID 490)
18/05/25 09:51:51 INFO ShuffleBlockFetcherIterator: Getting 150 non-empty blocks out of 150 blocks
18/05/25 09:51:51 INFO ShuffleBlockFetcherIterator: Started 5 remote fetches in 2 ms
18/05/25 09:51:51 INFO Executor: Finished task 116.0 in stage 2.0 (TID 416). 4094 bytes result sent to driver
18/05/25 09:51:51 INFO CoarseGrainedExecutorBackend: Got assigned task 492
18/05/25 09:51:51 INFO Executor: Running task 192.0 in stage 2.0 (TID 492)
18/05/25 09:51:51 INFO ShuffleBlockFetcherIterator: Getting 150 non-empty blocks out of 150 blocks
18/05/25 09:51:51 INFO ShuffleBlockFetcherIterator: Started 5 remote fetches in 2 ms
18/05/25 09:51:53 INFO Executor: Finished task 132.0 in stage 2.0 (TID 432). 4094 bytes result sent to driver
18/05/25 09:51:53 INFO CoarseGrainedExecutorBackend: Got assigned task 498
18/05/25 09:51:53 INFO Executor: Running task 198.0 in stage 2.0 (TID 498)
18/05/25 09:51:53 INFO ShuffleBlockFetcherIterator: Getting 150 non-empty blocks out of 150 blocks
18/05/25 09:51:53 INFO ShuffleBlockFetcherIterator: Started 6 remote fetches in 14 ms
18/05/25 09:51:58 INFO Executor: Finished task 150.0 in stage 2.0 (TID 450). 4094 bytes result sent to driver
18/05/25 09:52:01 INFO Executor: Finished task 172.0 in stage 2.0 (TID 472). 4137 bytes result sent to driver
18/05/25 09:52:03 INFO Executor: Finished task 181.0 in stage 2.0 (TID 481). 4094 bytes result sent to driver
18/05/25 09:52:05 INFO Executor: Finished task 179.0 in stage 2.0 (TID 479). 4094 bytes result sent to driver
18/05/25 09:52:05 INFO Executor: Finished task 192.0 in stage 2.0 (TID 492). 4094 bytes result sent to driver
18/05/25 09:52:06 INFO Executor: Finished task 187.0 in stage 2.0 (TID 487). 4094 bytes result sent to driver
18/05/25 09:52:06 INFO Executor: Finished task 190.0 in stage 2.0 (TID 490). 4094 bytes result sent to driver
18/05/25 09:52:08 INFO Executor: Finished task 198.0 in stage 2.0 (TID 498). 4094 bytes result sent to driver


